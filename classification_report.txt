import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, classification_report
from emnist import extract_training_samples, extract_test_samples

# Load EMNIST dataset (letters subset)
print("Loading EMNIST dataset...")
x_train, y_train = extract_training_samples('letters')
x_test, y_test = extract_test_samples('letters')

# Normalize and preprocess data
x_train = x_train / 255.0
x_test = x_test / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Adjust labels to start from 0
y_train -= 1
y_test -= 1

# Convert labels to one-hot encoding
y_train_cat = to_categorical(y_train, num_classes=26)
y_test_cat = to_categorical(y_test, num_classes=26)

# Define CNN architecture
def create_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(26, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Leave-One-Out Cross-Validation
print("Starting Leave-One-Out Cross-Validation (LOOCV)...")
n_samples = x_train.shape[0]
true_labels = []
predicted_labels = []

for i in range(n_samples):
    # Leave one sample out
    x_val = x_train[i:i+1]
    y_val = y_train_cat[i:i+1]
    x_train_cv = np.delete(x_train, i, axis=0)
    y_train_cv = np.delete(y_train_cat, i, axis=0)

    # Train model
    model = create_model()
    model.fit(x_train_cv, y_train_cv, epochs=3, batch_size=64, verbose=0)

    # Evaluate on the left-out sample
    y_pred = np.argmax(model.predict(x_val), axis=-1)
    y_true = np.argmax(y_val, axis=-1)

    true_labels.append(y_true[0])
    predicted_labels.append(y_pred[0])

    if (i + 1) % 100 == 0:
        print(f"Processed {i + 1}/{n_samples} samples...")

# Evaluation metrics
print("\nEvaluating performance...")
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print("Confusion Matrix:")
print(conf_matrix)

accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)
print(f"Accuracy: {accuracy:.4f}")

classification_report_str = classification_report(true_labels, predicted_labels, target_names=[chr(i) for i in range(65, 91)])
print("Classification Report:")
print(classification_report_str)

# Save metrics
with open("classification_report.txt", "w") as f:
    f.write(classification_report_str)

# Note: This LOOCV implementation is computationally expensive. Consider using subsets or different strategies for larger datasets.
