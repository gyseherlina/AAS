import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score
from sklearn.model_selection import LeaveOneOut
from emnist import extract_training_samples, extract_test_samples

# Load EMNIST dataset
def load_emnist():
    # Extract samples for "ByClass" split of EMNIST
    X_train, y_train = extract_training_samples('byclass')
    X_test, y_test = extract_test_samples('byclass')

    # Normalize the images and reshape
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    X_train = X_train.reshape(-1, 28, 28, 1)
    X_test = X_test.reshape(-1, 28, 28, 1)

    # Convert labels to categorical
    num_classes = len(np.unique(y_train))
    y_train = to_categorical(y_train, num_classes)
    y_test = to_categorical(y_test, num_classes)

    return (X_train, y_train), (X_test, y_test), num_classes

# Define the CNN architecture
def create_cnn_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Perform Leave-One-Out Cross-Validation
def loocv_evaluation(X, y, model_fn):
    loo = LeaveOneOut()
    y_true, y_pred = [], []

    for train_index, test_index in loo.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model = model_fn()
        model.fit(X_train, y_train, epochs=1, verbose=0, batch_size=32)

        pred = model.predict(X_test)
        y_true.append(np.argmax(y_test, axis=1))
        y_pred.append(np.argmax(pred, axis=1))

    return y_true, y_pred

# Main function
def main():
    # Load the dataset
    (X_train, y_train), (X_test, y_test), num_classes = load_emnist()

    # Define model function
    input_shape = X_train.shape[1:]
    model_fn = lambda: create_cnn_model(input_shape, num_classes)

    # Perform LOOCV (for demonstration, using a subset for speed)
    subset_size = 100  # Adjust for speed in demonstration
    X_subset, y_subset = X_train[:subset_size], y_train[:subset_size]
    y_true, y_pred = loocv_evaluation(X_subset, y_subset, model_fn)

    # Evaluate performance
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()

    conf_matrix = confusion_matrix(y_true, y_pred)
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    print("Confusion Matrix:\n", conf_matrix)
    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("F1-Score:", f1)

if __name__ == "__main__":
    main()

